"""
ä½¿ç”¨é˜¿é‡Œç™¾ç‚¼ï¼ˆDashScopeï¼‰æµ‹è¯• MCP Streamable HTTP æœåŠ¡å™¨
"""
import asyncio
import os
import json
from typing import Any

# è®¾ç½® API Key
os.environ["DASHSCOPE_API_KEY"] = "your-token"

# æ¸…é™¤ä»£ç†è®¾ç½®
os.environ.pop("http_proxy", None)
os.environ.pop("https_proxy", None)
os.environ.pop("all_proxy", None)
os.environ.pop("HTTP_PROXY", None)
os.environ.pop("HTTPS_PROXY", None)
os.environ.pop("ALL_PROXY", None)

import httpx
from langchain_community.chat_models.tongyi import ChatTongyi
from langchain_core.messages import HumanMessage, AIMessage, ToolMessage

# MCP æœåŠ¡å™¨é…ç½®
MCP_SERVER_URL = "http://localhost:9898"


async def call_mcp_tool(tool_name: str, arguments: dict) -> dict:
    """è°ƒç”¨ MCP å·¥å…·ï¼ˆStreamable HTTP åè®®ï¼‰"""
    async with httpx.AsyncClient(trust_env=False, timeout=60.0) as client:
        response = await client.post(
            f"{MCP_SERVER_URL}/?_tool={tool_name}",
            headers={
                "Content-Type": "application/json",
                "Accept": "application/json, text/event-stream"
            },
            json={
                "jsonrpc": "2.0",
                "method": "tools/call",
                "params": {
                    "name": tool_name,
                    "arguments": arguments
                },
                "id": "test-1"
            }
        )
        response.raise_for_status()
        return parse_sse_response(response.text)


def parse_sse_response(text: str) -> dict:
    """è§£æ SSE æ ¼å¼çš„å“åº”"""
    lines = text.strip().split('\n')
    for line in lines:
        if line.startswith('data: '):
            data_str = line[6:]  # ç§»é™¤ 'data: ' å‰ç¼€
            return json.loads(data_str)
    raise ValueError("No data found in SSE response")


async def list_mcp_tools() -> list[dict]:
    """åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„ MCP å·¥å…·"""
    async with httpx.AsyncClient(trust_env=False, timeout=60.0) as client:
        response = await client.post(
            MCP_SERVER_URL,
            headers={
                "Content-Type": "application/json",
                "Accept": "application/json, text/event-stream"
            },
            json={
                "jsonrpc": "2.0",
                "method": "tools/list",
                "params": {},
                "id": "list-tools"
            }
        )
        response.raise_for_status()
        
        # è§£æ SSE å“åº”
        result = parse_sse_response(response.text)
        return result.get("result", {}).get("tools", [])


async def main():
    print("ğŸš€ å¼€å§‹æµ‹è¯• MCP + é˜¿é‡Œç™¾ç‚¼é›†æˆ...")
    
    # 1. åˆ—å‡ºå¯ç”¨å·¥å…·
    print(f"\nğŸ”Œ è¿æ¥åˆ° MCP æœåŠ¡å™¨: {MCP_SERVER_URL}")
    tools = await list_mcp_tools()
    print(f"âœ… å‘ç° {len(tools)} ä¸ªå·¥å…·")
    
    # è½¬æ¢ä¸º LangChain å·¥å…·æ ¼å¼
    lc_tools = []
    for tool in tools:
        lc_tool = {
            "type": "function",
            "function": {
                "name": tool["name"],
                "description": tool.get("description", ""),
                "parameters": tool.get("inputSchema", {})
            }
        }
        lc_tools.append(lc_tool)
        print(f"  - {tool['name']}")
    
    # 2. åˆå§‹åŒ–é˜¿é‡Œç™¾ç‚¼æ¨¡å‹
    print("\nğŸ¤– åˆå§‹åŒ–é˜¿é‡Œç™¾ç‚¼ (Qwen)...")
    llm = ChatTongyi(model="qwen-turbo")
    llm_with_tools = llm.bind_tools(lc_tools)
    
    # 3. æ‰§è¡Œæµ‹è¯•æŸ¥è¯¢
    # æ˜ç¡®å‘Šè¯‰ LLM ä½¿ç”¨ EXCHANGE:SYMBOL æ ¼å¼
    query = """å¸®æˆ‘æŸ¥ä¸€ä¸‹è´µå·èŒ…å°ç°åœ¨çš„ä»·æ ¼ï¼Œå¹¶åˆ†æä¸€ä¸‹å®ƒçš„åŸºæœ¬é¢æƒ…å†µã€‚

é‡è¦æç¤ºï¼š
- æŸ¥è¯¢è‚¡ç¥¨æ—¶ï¼Œticker å‚æ•°å¿…é¡»ä½¿ç”¨ "äº¤æ˜“æ‰€:è‚¡ç¥¨ä»£ç " æ ¼å¼
- è´µå·èŒ…å°çš„æ­£ç¡®æ ¼å¼æ˜¯ï¼šSSE:600519
- å…¶ä»–ç¤ºä¾‹ï¼šNASDAQ:BABA (é˜¿é‡Œå·´å·´), NYSE:TSLA (ç‰¹æ–¯æ‹‰), SZSE:000001 (å¹³å®‰é“¶è¡Œ)
"""
    print(f"\nâ“ ç”¨æˆ·æŸ¥è¯¢: {query}")
    
    messages = [HumanMessage(content=query)]
    
    # ç¬¬ä¸€æ¬¡ LLM è°ƒç”¨ - å†³å®šè°ƒç”¨å“ªäº›å·¥å…·
    print("â³ LLM æ­£åœ¨æ€è€ƒ...")
    response = llm_with_tools.invoke(messages)
    messages.append(response)
    
    # æ£€æŸ¥æ˜¯å¦è°ƒç”¨äº†å·¥å…·
    if response.tool_calls:
        print(f"\nğŸ› ï¸  LLM å†³å®šè°ƒç”¨ {len(response.tool_calls)} ä¸ªå·¥å…·:")
        
        for tool_call in response.tool_calls:
            tool_name = tool_call["name"]
            tool_args = tool_call["args"]
            tool_call_id = tool_call["id"]
            
            print(f"\n  > è°ƒç”¨å·¥å…·: {tool_name}")
            print(f"    å‚æ•°: {json.dumps(tool_args, ensure_ascii=False)}")
            
            # é€šè¿‡ MCP æ‰§è¡Œå·¥å…·
            try:
                result = await call_mcp_tool(tool_name, tool_args)
                
                # æå–å·¥å…·ç»“æœ - MCP è¿”å›æ ¼å¼: result.content[0].text
                if "result" in result and "content" in result["result"]:
                    content_items = result["result"]["content"]
                    if content_items and len(content_items) > 0:
                        # è·å–ç¬¬ä¸€ä¸ª content é¡¹çš„ text
                        tool_output = content_items[0].get("text", "")
                        print(f"    âœ… ç»“æœ: {tool_output[:200]}...")
                    else:
                        tool_output = json.dumps(result, ensure_ascii=False)
                        print(f"    âš ï¸  ç©ºå†…å®¹")
                else:
                    tool_output = json.dumps(result, ensure_ascii=False)
                    print(f"    âš ï¸  æ„å¤–æ ¼å¼: {tool_output[:200]}...")
                
                # æ·»åŠ å·¥å…·ç»“æœåˆ°æ¶ˆæ¯å†å²
                messages.append(ToolMessage(
                    content=tool_output,
                    tool_call_id=tool_call_id
                ))
            except Exception as e:
                print(f"    âŒ å·¥å…·è°ƒç”¨å¤±è´¥: {e}")
                import traceback
                traceback.print_exc()
                messages.append(ToolMessage(
                    content=f"å·¥å…·è°ƒç”¨å¤±è´¥: {str(e)}",
                    tool_call_id=tool_call_id
                ))
        
        # ç¬¬äºŒæ¬¡ LLM è°ƒç”¨ - ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ
        print("\nâ³ LLM æ­£åœ¨ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ...")
        final_response = llm_with_tools.invoke(messages)
        
        print("\n" + "="*60)
        print("ğŸ’¡ æœ€ç»ˆç­”æ¡ˆ:")
        print("="*60)
        print(final_response.content)
        print("="*60)
    else:
        print("\nâš ï¸  LLM æ²¡æœ‰è°ƒç”¨ä»»ä½•å·¥å…·")
        print(response.content)


if __name__ == "__main__":
    asyncio.run(main())
